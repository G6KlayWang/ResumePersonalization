{
    "3.pdf": "Udit Arora\nNew York, NY\nuditarora@nyu.edu\nhttps://uditarora.com\nEducation\nCourant Institute of Mathematical Sciences, New York University\nNew York, NY\nMaster of Science in Computer Science; GPA: 3.93/4.0\nJan 2020 – Dec 2021\nCourses: Machine Learning, Deep Learning, NLP, Distributed Systems, Security, Deep RL\nNetaji Subhas Institute of Technology, University of Delhi\nDelhi, India\nBachelor of Engineering in Computer Engineering\nAug 2012 – May 2016\nMerit Scholarship; Founding Member, NSIT Web Team\nExperience\nSalesforce\nSan Francisco, CA\nSoftware Engineering Intern\nJun 2021 - Aug 2021\n◦Incorporated past interactions as features in the Einstein Recommendation Builder (ERB) modeling pipeline.\n◦Streamlined ERB conﬁguration to improve adoption by supporting ERB Templates that use interactions.\nProduct Labs, IIIT Hyderabad\nHyderabad, India\nResearch Engineer\nJul 2019 - Dec 2019\n◦Productized commercially viable research output in collaboration with research labs at the institute.\n◦Implemented a pipeline for object detection and tracking in thermal images.\n◦Developed an end-to-end system for crowd-sourced speech data collection and transcription for 22 Indian languages.\n◦Architected a badminton player tracking tool used by Star Sports and a chatbot used by SBI (India’s largest bank).\nLaboratory for Computational Social Systems, IIIT Delhi\nDelhi, India\nResearch Assistant\nAug 2018 - Jul 2019\n◦Researched on user, content (tweet) and action (retweet/quote) level detection of blackmarket-driven collusive fraud\nfor gaining inorganic appraisals on Twitter using diﬀerent embedding methods and machine learning techniques.\nMicrosoft\nHyderabad, India\nSoftware Engineer\nJun 2016 - Jul 2018\n◦Excel: Developed innovative ways of sharing Excel content, later productionized as a part of the Fluid framework.\nEnabled integration of Excel with a messaging app and published a patent with the USPTO for the same.\n◦Kaizala: Delivered a time-driven release of Kaizala messaging app’s UWP application. Solved critical problems for\nworkﬂows like heterogeneous message views and custom cards to ensure good performance.\n◦Skype for Business: Developed the Cloud Call Analytics feature for Skype for Business Server 2019, building a\nsecure pipeline to upload call telemetry data online - among the most popular features of the 2019 release.\n◦Hackathon: Winner of the 2017 company-wide hackathon - created a utility to scan and analyze receipts in Excel.\nPublications\n• Arora, U., Huang, W., He, H. (2021), Types of Out-of-distribution texts and how to detect them. Proceedings of the\n2021 Conference on Empirical Methods in Natural Language Processing (EMNLP) (Acceptance rate: 23.4%)\n• Dutta, H., Arora, U., Chakraborty, T. (2021), ABOME: A Multi-platform Data Repository of Artiﬁcially Boosted\nOnline Media Entities. Proceedings of the International AAAI Conference on Web and Social Media (ICWSM)\n• Khullar, A.*, Arora, U.* (2020), MAST: Multimodal abstractive summarization with trimodal hierarchical attention.\nProceedings of the First EMNLP Workshop on NLP Beyond Text (* = equal contribution)\n• Arora, U., Dutta, H., Joshi, B., Chetan, A., Chakraborty, T. (2020), Analyzing and detecting collusive users involved in\nblackmarket retweeting activities. ACM Transactions on Intelligent Systems and Technology (Impact Factor: 3.971)\n• Arora, U. et. al. (2019), Multitask learning for blackmarket tweet detection. ASONAM 2019 (Acceptance rate: 15%)\nTechnical Skills and Academic Service\n• Languages: Python, C/C++, Javascript (JS), C#, Java\nOther: PyTorch, Keras, scikit-learn, Spark, MySQL, Git\n• Program Committee: EMNLP Workshop on NLP Beyond Text, 2020\n\nProjects\n• Out-of-distribution Methods for NLP: Collaborating with researchers from ML2 Lab (NYU) to develop methods to\nevaluate model robustness on out-of-distribution/anomalous text data across diﬀerent types of distribution shifts.\n• Multimodal Text Summarization: Text summarization using diﬀerent modalities of a video - designed and\nimplemented a hierarchical attention based architecture that achieved SOTA results. (link)\n• Covid News Analyzer: A web-based tool for analysis of Covid-19 articles on diﬀerent metrics using ML. (link)\n• Fashion Product Classiﬁcation: Classiﬁcation of fashion product images using convolutional neural networks with\nmultitask learning, utilizing product metadata to improve accuracy by 3.27%. (link)\n• Automated Cricket Umpire: A tool to visualize ball trajectory and make cricket umpiring decisions from a single\nsmartphone camera feed - used OpenCV for the ball tracking mechanism and Python for visualization. (link)\n• Guidance System for Visually Impaired: A Raspberry Pi based device to detect crosswalks/staircases using\ncomputer vision, and a companion android app to activate the device and provide haptic feedback to users. (link)\n• Chain Reaction Single Player: An Android game with bots of 10 diﬃculty levels that use a modiﬁed minimax\nalgorithm with probability-based selection for faster computation - 10,000+ users and coverage by tech blogs. (link)\n• NSIT Percentage Calculator: A web-app for analyzing college grades - used by 20,000+ NSIT students. (link)\n\n",
    "2.pdf": " \n \n \n \n \n \n \nYi Ao (Jack) Lu \n \nEducation                                             \n \n    New York University                                                                                                              Sept 2023 - Present \n    PhD Computer Science \n    Advised by: Mengye Ren \n    Research focus: deep generative models, few-shot learning, representation learning, concept learning  \n \n    University of Waterloo                                                                                                       Sept 2018 – May 2023 \n    BMATH Computer Science, Honours, Co-op \n    BMATH Statistics, Honours, Co-op \n    BMATH Combinatorics & Optimization, Joint Honours, Co-op                      Overall Cumulative GPA 95.62% \n \nResearch Experience \n \n    Research Intern | Waabi                                                                           Toronto, Canada | Sep 2022 – present \n    Supervised by Prof. Raquel Urtasun \n• \nConducting research for traffic scene generation with set-generation models, deep generative models, and \ngraph neural networks \n• \nDeveloped SceneControl: a novel diffusion model for realistic and controllable traffic scene generation \n \n    Research Intern | NVIDIA                                                                   Toronto, Canada | Sep 2021 – Mar 2022 \n    Supervised by Prof. Sanja Fidler \n• \nConducted research for improving AV perception models with synthetic data training, domain adaptation \nmethods, and domain randomization techniques \n• \nAchieved significant mAP improvement on the nuScenes 3D object detection dataset through domain-\nadversarial training techniques and novel asset-randomization methods \n• \nEngineered a data evaluation pipeline with all major distribution matching metrics (e.g., IS, FID, KID) \n \n    Deep Learning Engineer | DarwinAI                                                                  Remote | Sep 2020 – Dec 2020 \n    Supervised by Prof. Alexander Wong \n• \nDeveloped Fibrosis-Net: a pulmonary fibrosis progression prediction network for clients in the \npharmaceutical industry \n• \nConducted investigation in distributed training performance of computer vision models with Slurm and \nHorovod. Significantly improved distributed training performances of various computer vision models \n \nResearch Assistant | Vision and Image Processing Lab                  Waterloo, Canada | Sep 2019 – Dec 2019 \nSupervised by Prof. David Clausi \n• \nDeveloped object detection and classification models for hockey player identification and jersey number \nrecognition from hockey game footage \n \nyiaolu \n+1 778-898-0831 \nJacklu0831 \nyl11330@nyu.edu \n\n\f\n\f\n\f\n\f\n \n \n \nIndustry Experience \n \n    Deep Learning Engineer | NVIDIA                                                                   Remote | May 2021 – Aug 2021 \n• \nReduced the failure rate of NVIDIA autonomous vehicle’s path detection model by 21% by training it \nagainst synthetic data with adversarial scenarios. \n• \nAccelerated collision detection in NVIDIA DriveSim by ~7 times with a quadtree-based search algorithm. \n• \nEngineered scene randomization interfaces in NVIDIA DriveSim with support for 5+ diversity features (e.g., \nlighting, object placement); scaled data generation to 2M+ frames for training AV perception DNNs. \n \n    Cognitive Software Developer | IBM                                                    Ottawa, Canada | Jan 2020 – Apr 2020 \n• \nDeveloped and deployed a tabular data column clustering algorithm with word embeddings and ontology \ntrees. Co-authored a patent application on the novel approach. \n• \nSignificantly improved IBM Cognos Analytics chatbot’s NER model accuracy with BERT model backbone. \n \n    Full Stack Developer | Deep Trekker                                              Kitchener, Canada | May 2019 – Aug 2019 \n• \nEngineered a location tracking application with OpenStreetMap API that allows remote tracking of robots. \n• \nRefactored robot controller UI/UX with custom QML templates, reducing the codebase by over 30%. \n \nPublications \n \nJack Lu*, Ryan Teehan, Mengye Ren. ProCreate, Don't Reproduce! Propulsive Energy Diffusion for \nCreative Generation. In European Conference on Computer Vision (ECCV), 2024 \n \nJack Lu*, Kelvin Wong*, Chris Zhang, Simon Suo, Raquel Urtasun. SceneControl: Diffusion for \nControllable Traffic Scene Generation. In International Conference on Robotics and Automation \n(ICRA), 2024 \n \nAlexander Wong, Jack Lu, Adam Dorfman, Paul McInnis, Mahmoud Famouri, Daniel Manary, James Ren \nHou Lee, Michael Lynch. Fibrosis-Net: A Tailored Deep Convolutional Neural Network Design for Prediction \nof Pulmonary Fibrosis Progression from Chest CT Images. In Frontier in Artificial Intelligence, 2021 \n \nAwards \n \n    Winston and Diana Cherry Scholarship - $2,250                                                                                             2023 \n    Engineering Faculty/Staff Upper Year Scholarship - $500                                                                              2021 \n    President’s Research Award - $1,500                                                                                                              2020 \n    University of Waterloo President’s Scholarship of Distinction – $5,000                                                        2019            \n    Term Dean’s Honours List/Term Distinction (all undergraduate terms)                                                         2018 \n \nSkills \n \n    Languages: Python, C++, C, Scala, JavaScript, Java, R, SQL, HTML, CSS \n    Libraries/Frameworks: PyTorch, Tensorflow, Keras, Scikit-learn, Pandas \n    Others: Docker, Slurm, Spark, Hadoop, Bazel, Linux \n\n",
    "5.pdf": "Hoang Phan\nÔ 646-508-0988 | R phanviethoang1512@gmail.com | h viethoang1512.github.io | ° hoang-pv |  VietHoang1512\nEducation\nNew York University\nNew York, USA\nPh.D., Data Science, Advisors: Qi Lei, Andrew Gordon Wilson.\nSept. 2023 - Present\nHanoi University of Science and Technology\nHanoi, Vietnam\nB.Sc., Computer Science, Honor program.\nAug. 2018 - Aug. 2022\nExperience\nAmazon\nPalo Alto, USA\nApplied Scientist Intern\nMay. 2024 - Aug. 2024\nMentors: Colin Lockard, Yifan Gao, Rongmei Lin\n• Proposed a general framework for the data mixture problem that obtains SOTA performance, speeding up the\npretraining of LLMs by 35%.\nVinAI Research\nHanoi, Vietnam\nResearch resident\nAug. 2021 - Feb. 2023\nAdvisor: Trung Le\n• Main research topics: Robust machine learning, Transfer learning, Multi-task learning, Self-supervised learning.\n• Participated in a Smart City project that aims to build a kidnapping and unshielded truck detection system.\nData Science Laboratory\nSoICT-HUST\nUndergraduate research student\nSep. 2019 - Aug. 2021\nAdvisors: Khoat Than, Huong Le Thanh, Linh Ngo Van\n• Main research topics: Probabilistic inference, Continual learning.\n• Developed a Khmer processing toolkit (> 40.000 downloads and installations), supporting Asian Language machine\ntranslation. Used in Meta Research projects (NLLB, LASER, stopes), NAACL Workshop and 40+ other projects.\nCinnamon Inc\nHanoi, Vietnam\nAI research engineer\nJan. 2020 - June. 2021\n• Worked on information extraction of business documents and meta-learning, question-answering system research.\n• Developed an internal usage chatbot, integrated with Slack, in support of the Human Resource department.\nPublications\n• Yijun Dong∗, Hoang Phan∗, Xiang Pan∗and Qi Lei. “Sketchy Moment Matching: Toward Fast and Provable Data\nSelection for Finetuning”. In Advances in Neural Information Processing Systems, 2024. [pdf]\n• Hoang Phan∗, Lam Tran∗, Quyen Tran∗and Trung Le. “Enhancing Domain Adaptation through Prompt Gradient\nAlignment”. In Advances in Neural Information Processing Systems, 2024. [pdf]\n• Hao Phung, Quan Dao, Trung Dao, Hoang Phan, Dimitris N. Metaxas, Anh Tran. “DiMSUM: Diffusion Mamba -\nA Scalable and Unified Spatial-Frequency Method For Image Generation.” In Advances in Neural Information\nProcessing Systems, 2024.\n• Yijun Dong∗, Xiang Pan∗, Hoang Phan∗and Qi Lei. “Randomly Pivoted V-optimal Design: Fast Data Selection\nunder Low Intrinsic Dimension”. In Machine Learning and Compression Workshop at NeurIPS, 2024.\n• Hoang Phan, Andrew Gordon Wilson, Qi Lei. “Controllable Prompt Tuning for Balancing Group Distributional\nRobustness”. In International Conference on Machine Learning, 2024. [pdf]\n• Anh Nguyen, Long Vuong, Hoang Phan, Toan Do, Dinh Phung and Trung Le. “Flat Seeking Bayesian Neural\nNetworks”. Advances in Neural Information Processing Systems, 2023. [pdf]\n• Hoang Phan, Trung Le, Trung Phung, Anh Bui, Nhat Ho and Dinh Phung. “Global-Local Regularization Via\nDistributional Robustness”. In International Conference on Artificial Intelligence and Statistics, 2023. [pdf]\n• Hoang Phan, Ngoc Tran, Trung Le, Toan Tran, Nhat Ho and Dinh Phung. “Stochastic Multiple Target Sampling\nGradient Descent”. In Advances in Neural Information Processing Systems, 2022. [pdf]\n• Hoang Phan∗, Anh Phan∗, Son Nguyen∗, Linh Ngo Van and Khoat Than. “Reducing Catastrophic Forgetting in\nNeural Networks via Gaussian Mixture Approximation”. In Advances in Knowledge Discovery and Data Mining.\nPAKDD. Lecture Notes in Computer Science. Springer, 2022. [pdf]\n\n• Hoang Phan, Long Nguyen, Long Nguyen, and Khanh Doan. “Matching The Statements: A Simple and Accurate\nModel for Key Point Analysis”. In Proceedings of the 8th Workshop on Argument Mining at EMNLP, 2021. [pdf]\n• Tam Nguyen, Quang Pham, Linh Doan, Hoang Trinh, Anh Nguyen and Hoang Phan. “Contrastive Learning for\nNatural Language-Based Vehicle Retrieval”. In Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition Workshops at CVPR, 2021. [pdf]\n• Quang Pham, Hoang Phan, Hoang Trinh, Anh Nguyen and Hoai Nguyen. “S-NLP at ICDAR 2021: Multimodal\nEmotion Recognition on Comics scenes”. In International Conference on Document Analysis and Recognition\nWorkshops. Technical report. [pdf]\nPreprints\n• Hoang Phan, Lam Tran, Ngoc Tran, Nhat Ho, Dinh Phung and Trung Le. “Improving Multi-task Learning via\nSeeking Task-based Flat Regions”. Under review. [pdf]\n• Ngoc Tran, Son Duong, Hoang Phan, Tung Pham, Dinh Phung and Trung Le. “Sharpness & Shift-Aware\nSelf-Supervised Learning”. Under review. [pdf]\n• Ngoc Tran, Lam Tran, Hoang Phan, Anh Bui, Tung Pham, Toan Tran, Dinh Phung and Trung Le. “Robust\nContrastive Learning With Theory Guarantee”. Under review. [pdf]\n• Quyen Tran, Hoang Phan, Khoat Than, Dinh Phung and Trung Le. “Continual Learning with Optimal Transport\nbased Mixture Model”. Under review. [pdf]\n(∗) denotes equal contribution\nAchievements\nArgMining: Key Point Analysis Shared Task, EMNLP\n2021\nPresented the 4th solution in the workshop, hosted by IBM Research AI team.\nNVIDIA AI City Challenge: Natural Language-Based Vehicle Retrieval, CVPR\n2021\nGot the 4th place with a Siamese model capable of extracting visual concepts from natural language.\nMultimodal Emotion Recognition on Comics scenes, ICDAR\n2021\nWon the first prize with a late fusion model, combined the processing of multiple input modalities.\nReliable Intelligence Identification on Vietnamese SNSs, VLSP\n2020\nAchieved a competitive performance (ranked 4th) in the VLSP shared task.\nCredit Scoring Challenge, Kalapa. Jsc\n2020\nTeam ranked 1/146 with 800 contestants in constructing a banking credit scoring system.\nUniversity of Liverpool - Ion Switching, Kaggle\n2020\nBronze medalist (solo) in the University of Liverpool’s Institute of Ageing and Chronic Disease competition.\nPractical deep learning, Vietnam Institute for Advanced Study in Mathematics\n2019\nDeveloped a deep learning-based Vietnamese spell corrector and ranked 1/50 in the final-project defense.\nNational/international prize\nNational Olympiad for Students\n2017 - 2018\nVietnam Mathematical Society (VMS) Olympiad for universities and high school students\n• Gold medal (2018), Silver medal (2017).\nVietnam Mathematics Olympiad (VMO)\n2017 - 2018\nThe annual national mathematics competition for high school students\n• Second prize (2018), Third prize (2017).\n• International Mathematics Olympiad team selection test contestant.\nInternational Tournament of Towns (ITOT)\n2017\nInternational mathematical Olympiad for school students\n• Bronze medal (2017).\nVietnam Institute for Advanced Study in Mathematics (VIASM) Scholarship\n2016 - 2018\nScholarship of the National Program for the Development of Mathematics\nVallet Scholarship\n2017 - 2018\nOdon Vallet’s scholarships for outstanding Vietnamese students\nProfessional services\nReviewer at NeurIPS 2023, ICCV 2023, ECCV 2024, ICLR 2024, ICLR 2025, WACV 2025.\n\n",
    "1.pdf": "Tomisin Adeyemi\ntomisinadeyemi7@gmail.com | linkedin.com/in/ota231 | github.com/ota231\nEducation\nNew York University\nNew York, NY\nBA in Computer & Data Science (Honors), Minor in Mathematics | GPA: 3.7\nSep. ’21 – May ’25\n• Relevant Coursework: CS: Data Structures, Basic Algorithms, Operating Systems Math: Calculus, Linear\nAlgebra, Probability & Stats. Data/AI: Intro to Data Science, Machine Learning, Deep Learning, NLP, Data\nManagement & Analysis, Causal Inference, Responsible Data Science, AI Research, Predictive Analytics (Grad)\n• Awards & Honors: Presidential Honors Scholar (Top 10%), Davis Scholar ($35,000 scholarship)\n• Clubs & Affiliations: Colorstack, Rewriting the Code, Headstart (Mentor), NYU Women In Science\nExperience\nIncoming Software Engineering Intern\nMay ’24\nNetflix\nLos Gatos, CA\nUndergraduate Teaching Assistant\nSep. ’22 – Present\nNew York University\nNew York, NY\n• Provide in-class tutoring for 80+ students and hold office hours open to 600+ students, for the course\nIntroduction to Computer Programming (in Python).\n• Created supplemental lecture materials using Google Colab notebooks, providing additional opportunities for\nstudents to reinforce programming skills.\n• Helped students build problem-solving skills by breaking down complex programming problems into\nmanageable steps and encouraging them to think critically about problem solving approaches.\nSoftware Engineering Intern\nJun. ’23 – Aug. ’23\nAmazon\nSeattle, WA\n• Enhanced AWS Aurora GlobalDB API architecture to incorporate recovery of misconfigured encrypted clusters\ninto existing workflows, benefiting 30,000+ customers in the most popular AWS Region.\n• Demonstrated exceptional problem-solving skills by innovating a cross-functional solution that surpassed initial\nengineering recommendations, effectively resolving multi-team issues.\n• Achieved stretch goal by developing an automated recovery feature that utilized initial architectural\nimprovements to seamlessly recover clusters without customer intervention.\n• Skills Used: Backend Development, Systems Design, Java, Object-Oriented Programming, UNIX CLI, Spring, AWS\nRDS, AWS KMS, & Git\nProjects\nLinguistic Features & Multi-label Emotion Classification | spaCy, NLTK, scikit-learn\nApr. ’23 – May ’23\n• Led 4-member team to write the code and paper for an NLP research project assessing the effectiveness of\nlinguistic features for emotion classification.\n• Preprocessed 50k-row dataset, leveraging TFIDF with unigrams for feature extraction; additionally engineering\ncustom textual features for model training.\n• Trained and tuned logistic regression, SVM, KNN, Random Forest, and XGBoost models.\n• Achieved 89.03% Multilabel Accuracy and 58.91% Micro-F1 score, outperforming baseline BERT model by 8%.\nMiscellaneous Operating System Projects | C, C++, Git, Docker, gdb\nJan. ’23 – May ’23\n• Achieved grades of 90 to 100% in bi-weekly projects from my Operating Systems class, covering C programming,\nMulti-Threaded Programming, File Systems, UNIX and Virtual Memory.\nMiscellaneous Machine Learning Projects | Python, Spyder, scikit-learn, PyTorch\nJan. ’23 – May ’23\n• Achieved grades of 100% or higher (with extra credit) on projects from my Machine Learning Class covering\nRegression, Classification, Clustering, Dimension Reduction & Deep Learning algorithms/techniques.\n• Libraries used: pandas, numpy, scikit-learn, PyTorch, seaborn, matplotlib\nMovie Recommendation System Kaggle Competition | scikit-surprise\nJan. ’23 – Apr. ’23\n• Led 4-member team to build movie recommendation system using content-based filtering, collaborative\nfiltering and matrix factorization techniques.\n• Collaborated to clean, preprocess, and merge 3 datasets totaling 60k rows, utilizing duplicate identification and\ndata imputation techniques to optimize model performance.\n• Placed 4th out of 15 teams in NYC, with a Root Mean Squared Error of only 17.97%.\nTechnical Skills\nLanguages: Python (pandas, NumPy, Matplotlib, scikit-learn, PyTorch), Java, C, C++ (familiar), R (familiar)\nDeveloper Tools: Git, Docker, UNIX, Regex | Databases: SQL, MongoDB, PostgreSQL, pgAdmin\n\n",
    "4.pdf": "Chris Hoang\nch3451@nyu.edu · chrishoang.com\nEDUCATION\nNew York University\nSep 2023 – May 2028\nPh.D. in Computer Science (3.89/4.00 GPA)\n• Advised by Mengye Ren\nUniversity of Michigan\nSep 2016 – May 2020\nB.S.E., M.S.E. in Computer Science and Engineering (4.00/4.00 GPA)\n• Advised by Honglak Lee and Michael P. Wellman\nHONORS AND AWARDS\nNDSEG Fellowship ($130,000 award)\n2024 - 2027\nTuck & Ham-Hi Lee and Sheldon Howard & Ruth Hoff Grants ($80,000 award)\n2016 - 2020\nD.E. Shaw Nexus Fellowship ($1,500 award)\n2018\nWilliam J. Branstrom Freshman Prize (top 5% of freshman class)\n2016\nPUBLICATIONS\nPooDLe: Pooled and dense self-supervised learning from naturalistic videos\nP\nAlex N. Wang*, Chris Hoang*, Yuwen Xiong, Yann LeCun, Mengye Ren\nPreprint\nSuccessor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning\nP\nChris Hoang, Sungryull Sohn, Jongwook Choi, Wilka Carvalho, Honglak Lee\nNeurIPS 2021\nSpoofing the Limit Order Book: A Strategic Agent-Based Analysis\nP\nXintong Wang, Chris Hoang, Yevgeniy Vorobeychik, Michael P. Wellman\nGames 2021\nLearning-Based Trading Strategies in the Face of Market Manipulation\nP\nXintong Wang, Chris Hoang, Michael P. Wellman\nICAIF 2020\nRESEARCH EXPERIENCE\nNew York University CILVR Lab\nDec 2022 – Present\nResearch Assistant, Advisor: Mengye Ren\n• Designed a new method that unifies pooled invariance and dense SSL objectives within a spatial decoder\narchitecture to learn visual representations for segmentation and object detection from naturalistic dense videos\nUniversity of Michigan AI Lab\nJun 2019 – Sep 2021\nResearch Assistant, Advisor: Honglak Lee\n• Led research team to develop method that leverages a latent representation of transition dynamics to abstract\nhigh-dimensional state spaces as landmark graphs, enabling exploration and long-horizon goal-reaching\nResearch Assistant, Advisor: Michael P. Wellman\nDec 2017 – Jun 2019\n• Formulated trading algorithms that can learn from market information in a manner robust to adversarial agents\nby analyzing simulations and equilibrium states of a multi-agent model of financial markets\nINDUSTRY EXPERIENCE\nThe Voleon Group\nOct 2020 – Jan 2023\nMachine Learning Engineer\n• Explored model selection, response construction, and feature engineering to improve stock return prediction\n• Analyzed simulations of trading strategies to mitigate exposure to macroeconomic factors and tail-risk events\nCitadel\nJun 2019 – Aug 2019\nSoftware Engineering Intern\n• Developed research infrastructure, analysis tooling, and data pipelines for experimenting with real-time\nfinancial data, portfolio optimization strategies, and econometric models of market risk factors\nAmazon\nJun 2018 – Aug 2018\nSoftware Development Engineer Intern\n\n• Architected framework for executing computer vision and robotics workflows from offline learning to real-time\ninference, using cache-enabled task graphs and dynamic job scheduling to achieve computational scalability\nPROJECTS\nReconstruction-Driven Curiosity\n• Developed reward signal based on visual reconstruction to encourage exploration in Atari games\nPredicting Temporal Ordering of Video Frames\n• Designed temporal ordering training signal for learning motion-related features from video data\nMENTORSHIP\nJenny Zhu, NYU GSTEM - Video Semantic Labeling\n2024\nADDITIONAL\nAlumnus of Thomas Jefferson High School for Science and Technology\nTechnical Skills: Python, PyTorch, TensorFlow, R, C++, C\nLast updated on October 8, 2024\n\n"
}
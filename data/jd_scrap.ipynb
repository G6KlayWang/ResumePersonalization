{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\crepe-0.0.15-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gluonts 0.14.4 requires pandas<2.2.0,>=1.0, but you have pandas 2.2.2 which is incompatible.\n",
      "langchain-community 0.3.5 requires langchain<0.4.0,>=0.3.6, but you have langchain 0.0.319 which is incompatible.\n",
      "langchain-community 0.3.5 requires langsmith<0.2.0,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\n",
      "langchain-core 0.3.15 requires langsmith<0.2.0,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\n",
      "langchain-ollama 0.1.1 requires langchain-core<0.3.0,>=0.2.20, but you have langchain-core 0.3.15 which is incompatible.\n",
      "langchain-openai 0.2.6 requires openai<2.0.0,>=1.54.0, but you have openai 0.28.0 which is incompatible.\n",
      "pytorch-accelerated 0.1.49 requires accelerate==0.29.3, but you have accelerate 1.1.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-jobspy\n",
      "  Downloading python_jobspy-1.1.76-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting NUMPY==1.26.3 (from python-jobspy)\n",
      "  Downloading numpy-1.26.3-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\program files\\python311\\lib\\site-packages (from python-jobspy) (4.12.3)\n",
      "Collecting markdownify<0.14.0,>=0.13.1 (from python-jobspy)\n",
      "  Downloading markdownify-0.13.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.0 in c:\\program files\\python311\\lib\\site-packages (from python-jobspy) (2.2.2)\n",
      "Collecting pydantic<3.0.0,>=2.3.0 (from python-jobspy)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Requirement already satisfied: regex<2025.0.0,>=2024.4.28 in c:\\program files\\python311\\lib\\site-packages (from python-jobspy) (2024.7.24)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\program files\\python311\\lib\\site-packages (from python-jobspy) (2.32.3)\n",
      "Collecting tls-client<2.0.0,>=1.0.1 (from python-jobspy)\n",
      "  Downloading tls_client-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\program files\\python311\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.2->python-jobspy) (2.6)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\mingyangwang\\appdata\\roaming\\python\\python311\\site-packages (from markdownify<0.14.0,>=0.13.1->python-jobspy) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\program files\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.3.0->python-jobspy) (0.7.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.3.0->python-jobspy)\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.3.0->python-jobspy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (2024.7.4)\n",
      "Downloading python_jobspy-1.1.76-py3-none-any.whl (38 kB)\n",
      "Downloading numpy-1.26.3-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 39.8 MB/s eta 0:00:00\n",
      "Downloading markdownify-0.13.1-py3-none-any.whl (10 kB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.6 MB/s eta 0:00:00\n",
      "Downloading tls_client-1.0.1-py3-none-any.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 12.3/41.3 MB 59.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 23.6/41.3 MB 57.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 33.6/41.3 MB 54.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 50.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tls-client, pydantic-core, NUMPY, pydantic, markdownify, python-jobspy\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: NUMPY\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "Successfully installed NUMPY-1.26.3 markdownify-0.13.1 pydantic-2.10.3 pydantic-core-2.27.1 python-jobspy-1.1.76 tls-client-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U python-jobspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 15:47:47,824 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-12-16 15:47:47,850 - INFO - JobSpy:LinkedIn - search page: 1 / 1\n",
      "2024-12-16 15:47:48,003 - INFO - JobSpy:ZipRecruiter - search page: 1 / 1\n",
      "c:\\Program Files\\Python311\\Lib\\site-packages\\markdownify\\__init__.py:104: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n",
      "2024-12-16 15:47:48,715 - INFO - JobSpy:Glassdoor - search page: 1 / 1\n",
      "2024-12-16 15:47:48,850 - INFO - JobSpy:Indeed - finished scraping\n",
      "2024-12-16 15:47:48,883 - INFO - JobSpy:Google - finished scraping\n",
      "2024-12-16 15:47:49,361 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
      "2024-12-16 15:47:49,997 - INFO - JobSpy:Glassdoor - finished scraping\n",
      "2024-12-16 15:48:03,432 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 jobs\n",
      "                 id       site  \\\n",
      "0  gd-1009567833310  glassdoor   \n",
      "1  gd-1009567818319  glassdoor   \n",
      "2  gd-1009567812905  glassdoor   \n",
      "3  gd-1009567830208  glassdoor   \n",
      "4  gd-1007136916667  glassdoor   \n",
      "\n",
      "                                             job_url job_url_direct  \\\n",
      "0  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "1  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "2  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "3  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "4  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "\n",
      "                                          title  \\\n",
      "0      Senior Software Engineer, Infrastructure   \n",
      "1            Senior Software Engineer, Compiler   \n",
      "2          Site Reliability Engineer - Remote -   \n",
      "3  Software Quality Assurance Engineer (Remote)   \n",
      "4                          Full Stack Developer   \n",
      "\n",
      "                              company          location date_posted job_type  \\\n",
      "0               Scott’s Cheap Flights               NaN  2024-12-16      NaN   \n",
      "1                       Category Labs               NaN  2024-12-16      NaN   \n",
      "2                              Akamai               NaN  2024-12-16      NaN   \n",
      "3  Pinnacle Software Consulting, Inc.     United States  2024-12-16      NaN   \n",
      "4                      eVideon Health  Grand Rapids, MI  2024-12-14      NaN   \n",
      "\n",
      "  salary_source  ...             emails  \\\n",
      "0   direct_data  ...  careers@going.com   \n",
      "1   direct_data  ...                NaN   \n",
      "2   direct_data  ...                NaN   \n",
      "3           NaN  ...                NaN   \n",
      "4   direct_data  ...                NaN   \n",
      "\n",
      "                                         description  company_industry  \\\n",
      "0  **About the Role**\\n------------------\\n\\n\\nAt...               NaN   \n",
      "1  Category Labs (formerly known as Monad Labs) i...               NaN   \n",
      "2  **Are you excited by the opportunity to monito...               NaN   \n",
      "3  **Responsibilities**\\n\\n* Functions as an indi...               NaN   \n",
      "4  Full Stack Developer\\n\\neVideon Healthcare is ...               NaN   \n",
      "\n",
      "                                         company_url  \\\n",
      "0  https://www.glassdoor.com/Overview/W-EI_IE2019...   \n",
      "1  https://www.glassdoor.com/Overview/W-EI_IE1634...   \n",
      "2  https://www.glassdoor.com/Overview/W-EI_IE9219...   \n",
      "3  https://www.glassdoor.com/Overview/W-EI_IE2300...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                        company_logo company_url_direct  \\\n",
      "0  https://media.glassdoor.com/sql/2019399/scott-...                NaN   \n",
      "1                                                NaN                NaN   \n",
      "2  https://media.glassdoor.com/sql/9219/akamai-sq...                NaN   \n",
      "3  https://media.glassdoor.com/sql/2300961/pinnac...                NaN   \n",
      "4                                                NaN                NaN   \n",
      "\n",
      "  company_addresses company_num_employees company_revenue company_description  \n",
      "0               NaN                   NaN             NaN                 NaN  \n",
      "1               NaN                   NaN             NaN                 NaN  \n",
      "2               NaN                   NaN             NaN                 NaN  \n",
      "3               NaN                   NaN             NaN                 NaN  \n",
      "4               NaN                   NaN             NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "\n",
    "jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
    "    search_term=\"software engineer\",\n",
    "    results_wanted=5,\n",
    "    hours_old=72,\n",
    "    country_indeed='USA',\n",
    "    linkedin_fetch_description=True\n",
    "    # linkedin_fetch_description=True # gets more info such as description, direct job url (slower)\n",
    "    # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    ")\n",
    "print(f\"Found {len(jobs)} jobs\")\n",
    "print(jobs.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"se.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"jobs_sde.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 23:12:33,274 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-12-11 23:12:33,292 - INFO - JobSpy:LinkedIn - search page: 1 / 3\n",
      "2024-12-11 23:12:33,437 - INFO - JobSpy:ZipRecruiter - search page: 1 / 2\n",
      "2024-12-11 23:12:33,818 - INFO - JobSpy:Glassdoor - search page: 1 / 1\n",
      "2024-12-11 23:12:34,085 - INFO - JobSpy:Indeed - finished scraping\n",
      "2024-12-11 23:12:34,100 - INFO - JobSpy:Google - search page: 1 / 3\n",
      "2024-12-11 23:12:34,700 - INFO - JobSpy:Google - search page: 2 / 3\n",
      "2024-12-11 23:12:35,062 - INFO - JobSpy:Google - finished scraping\n",
      "2024-12-11 23:12:35,167 - INFO - JobSpy:Glassdoor - finished scraping\n",
      "2024-12-11 23:12:39,666 - INFO - JobSpy:ZipRecruiter - search page: 2 / 2\n",
      "2024-12-11 23:12:40,638 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
      "2024-12-11 23:16:14,661 - INFO - JobSpy:LinkedIn - search page: 2 / 3\n",
      "2024-12-11 23:18:37,704 - INFO - JobSpy:LinkedIn - search page: 3 / 3\n",
      "2024-12-11 23:20:10,929 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 jobs\n",
      "                 id       site  \\\n",
      "0  gd-1009561647095  glassdoor   \n",
      "1  gd-1009562412037  glassdoor   \n",
      "2  gd-1009562235690  glassdoor   \n",
      "3  gd-1009561870856  glassdoor   \n",
      "4  gd-1009561805483  glassdoor   \n",
      "\n",
      "                                             job_url job_url_direct  \\\n",
      "0  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "1  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "2  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "3  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "4  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "\n",
      "                           title                   company     location  \\\n",
      "0           Analyst - AI Trainer            DataAnnotation  Modesto, CA   \n",
      "1  Business Intelligence Analyst                    Domotz          NaN   \n",
      "2               Business Analyst      ANDERSEN CONSULTANTS          NaN   \n",
      "3                   Data Analyst  PA Education Association          NaN   \n",
      "4            Senior Data Analyst        Coffee Meets Bagel          NaN   \n",
      "\n",
      "  date_posted job_type salary_source  ... emails  \\\n",
      "0  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "1  2024-12-11      NaN           NaN  ...    NaN   \n",
      "2  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "3  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "4  2024-12-11      NaN           NaN  ...    NaN   \n",
      "\n",
      "                                         description  company_industry  \\\n",
      "0  We are looking for a data analyst to join our ...               NaN   \n",
      "1  * Updated: December 2024\\n* Department: Operat...               NaN   \n",
      "2  ***Overview:***  \\nThe purpose of this team is...               NaN   \n",
      "3  Are you looking for a place where innovation a...               NaN   \n",
      "4  Coffee Meets Bagel is a women\\-founded, women\\...               NaN   \n",
      "\n",
      "                                         company_url  \\\n",
      "0  https://www.glassdoor.com/Overview/W-EI_IE8605...   \n",
      "1  https://www.glassdoor.com/Overview/W-EI_IE8457...   \n",
      "2  https://www.glassdoor.com/Overview/W-EI_IE8505...   \n",
      "3  https://www.glassdoor.com/Overview/W-EI_IE7568...   \n",
      "4  https://www.glassdoor.com/Overview/W-EI_IE9731...   \n",
      "\n",
      "                                        company_logo company_url_direct  \\\n",
      "0  https://media.glassdoor.com/sql/8605843/dataan...                NaN   \n",
      "1  https://media.glassdoor.com/sql/845735/domidom...                NaN   \n",
      "2                                                NaN                NaN   \n",
      "3  https://media.glassdoor.com/sql/756847/tribuna...                NaN   \n",
      "4  https://media.glassdoor.com/sql/973161/coffee-...                NaN   \n",
      "\n",
      "  company_addresses company_num_employees company_revenue company_description  \n",
      "0               NaN                   NaN             NaN                 NaN  \n",
      "1               NaN                   NaN             NaN                 NaN  \n",
      "2               NaN                   NaN             NaN                 NaN  \n",
      "3               NaN                   NaN             NaN                 NaN  \n",
      "4               NaN                   NaN             NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "\n",
    "jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
    "    search_term=\"data analyst\",\n",
    "    results_wanted=25,\n",
    "    hours_old=72,\n",
    "    country_indeed='USA',\n",
    "    linkedin_fetch_description=True\n",
    "    # linkedin_fetch_description=True # gets more info such as description, direct job url (slower)\n",
    "    # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    ")\n",
    "print(f\"Found {len(jobs)} jobs\")\n",
    "print(jobs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"jobs_da.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 15:50:41,885 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-12-16 15:50:41,898 - INFO - JobSpy:LinkedIn - search page: 1 / 1\n",
      "2024-12-16 15:50:42,030 - INFO - JobSpy:ZipRecruiter - search page: 1 / 1\n",
      "2024-12-16 15:50:42,526 - INFO - JobSpy:Glassdoor - search page: 1 / 1\n",
      "2024-12-16 15:50:42,767 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
      "2024-12-16 15:50:42,964 - INFO - JobSpy:Indeed - finished scraping\n",
      "2024-12-16 15:50:42,973 - INFO - JobSpy:Google - finished scraping\n",
      "2024-12-16 15:50:46,442 - INFO - JobSpy:Glassdoor - finished scraping\n",
      "2024-12-16 15:50:47,136 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 jobs\n",
      "                 id       site  \\\n",
      "0  gd-1009567327821  glassdoor   \n",
      "1  gd-1009567679406  glassdoor   \n",
      "2  gd-1009566302884  glassdoor   \n",
      "3  gd-1009565834275  glassdoor   \n",
      "4  gd-1009565851831  glassdoor   \n",
      "\n",
      "                                             job_url job_url_direct  \\\n",
      "0  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "1  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "2  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "3  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "4  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "\n",
      "                                        title                  company  \\\n",
      "0            Senior Machine Learning Engineer           Work from Home   \n",
      "1                Cybersecurity Data Scientist          Hunter Strategy   \n",
      "2           Sr. Associate - Kore.AI developer                Cognizant   \n",
      "3  AI Math Analyst - Part Time Work From Home               Outlier Ai   \n",
      "4                              Data Scientist  Legal & General America   \n",
      "\n",
      "        location date_posted job_type salary_source  ... emails  \\\n",
      "0  Nashville, TN  2024-12-16      NaN   direct_data  ...    NaN   \n",
      "1            NaN  2024-12-16      NaN           NaN  ...    NaN   \n",
      "2    Teaneck, NJ  2024-12-15      NaN   direct_data  ...    NaN   \n",
      "3     Aurora, IL  2024-12-14      NaN   direct_data  ...    NaN   \n",
      "4  Frederick, MD  2024-12-14      NaN   direct_data  ...    NaN   \n",
      "\n",
      "                                         description  company_industry  \\\n",
      "0  ##### **Introduction**\\n\\n\\nDo you have the ca...               NaN   \n",
      "1  **About Hunter Strategy****Hunter Strategy has...               NaN   \n",
      "2  We are seeking a highly skilled Sr. Developer ...               NaN   \n",
      "3  **Outlier helps the world’s most innovative co...               NaN   \n",
      "4  Overview:\\n\\nAt Legal \\& General America, we a...               NaN   \n",
      "\n",
      "                                         company_url  \\\n",
      "0  https://www.glassdoor.com/Overview/W-EI_IE4760...   \n",
      "1  https://www.glassdoor.com/Overview/W-EI_IE3248...   \n",
      "2  https://www.glassdoor.com/Overview/W-EI_IE8014...   \n",
      "3  https://www.glassdoor.com/Overview/W-EI_IE2858...   \n",
      "4  https://www.glassdoor.com/Overview/W-EI_IE6657...   \n",
      "\n",
      "                                        company_logo company_url_direct  \\\n",
      "0                                                NaN                NaN   \n",
      "1  https://media.glassdoor.com/sql/3248996/hunter...                NaN   \n",
      "2  https://media.glassdoor.com/sql/8014/cognizant...                NaN   \n",
      "3  https://media.glassdoor.com/sql/2858115/outlie...                NaN   \n",
      "4  https://media.glassdoor.com/sql/665702/legal-a...                NaN   \n",
      "\n",
      "  company_addresses company_num_employees company_revenue company_description  \n",
      "0               NaN                   NaN             NaN                 NaN  \n",
      "1               NaN                   NaN             NaN                 NaN  \n",
      "2               NaN                   NaN             NaN                 NaN  \n",
      "3               NaN                   NaN             NaN                 NaN  \n",
      "4               NaN                   NaN             NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "\n",
    "jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
    "    search_term=\"data scientist\",\n",
    "    results_wanted=5,\n",
    "    hours_old=72,\n",
    "    country_indeed='USA',\n",
    "    linkedin_fetch_description=True\n",
    "    # linkedin_fetch_description=True # gets more info such as description, direct job url (slower)\n",
    "    # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    ")\n",
    "print(f\"Found {len(jobs)} jobs\")\n",
    "print(jobs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"DS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"jobs_ds.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 23:36:38,803 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-12-11 23:36:38,806 - INFO - JobSpy:LinkedIn - search page: 1 / 3\n",
      "2024-12-11 23:36:38,914 - INFO - JobSpy:ZipRecruiter - search page: 1 / 2\n",
      "2024-12-11 23:36:39,319 - INFO - JobSpy:Google - search page: 1 / 3\n",
      "2024-12-11 23:36:39,856 - INFO - JobSpy:Indeed - finished scraping\n",
      "2024-12-11 23:36:39,954 - INFO - JobSpy:Glassdoor - search page: 1 / 1\n",
      "2024-12-11 23:36:39,971 - INFO - JobSpy:Google - search page: 2 / 3\n",
      "2024-12-11 23:36:40,296 - INFO - JobSpy:Google - finished scraping\n",
      "2024-12-11 23:36:41,177 - INFO - JobSpy:Glassdoor - finished scraping\n",
      "2024-12-11 23:36:44,964 - INFO - JobSpy:ZipRecruiter - search page: 2 / 2\n",
      "2024-12-11 23:36:45,920 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
      "2024-12-11 23:37:09,068 - ERROR - JobSpy:LinkedIn - LinkedIn: HTTPSConnectionPool(host='www.linkedin.com', port=443): Max retries exceeded with url: /jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=data+engineer&distance=50&pageNum=0&start=0&f_TPR=r259200 (Caused by ResponseError('too many 429 error responses'))\n",
      "2024-12-11 23:37:09,069 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 jobs\n",
      "                 id       site  \\\n",
      "0  gd-1009562410163  glassdoor   \n",
      "1  gd-1009562237658  glassdoor   \n",
      "2  gd-1009562199060  glassdoor   \n",
      "3  gd-1009562197148  glassdoor   \n",
      "4  gd-1009561365067  glassdoor   \n",
      "\n",
      "                                             job_url job_url_direct  \\\n",
      "0  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "1  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "2  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "3  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "4  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "\n",
      "                                           title            company  \\\n",
      "0  Bioinformatics Data Engineer - Open to Remote     Synthesize Bio   \n",
      "1                           Senior Data Engineer  AgreeYa Solutions   \n",
      "2         Sr Data Engineer (PostgreSQL) - Remote              Optum   \n",
      "3             Data Engineer, Implementation Team          Coursedog   \n",
      "4                           Senior Data Engineer      ASET Partners   \n",
      "\n",
      "         location date_posted job_type salary_source  ... emails  \\\n",
      "0     Seattle, WA  2024-12-11      NaN           NaN  ...    NaN   \n",
      "1             NaN  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "2  California, MD  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "3             NaN  2024-12-11      NaN           NaN  ...    NaN   \n",
      "4             NaN  2024-12-11      NaN           NaN  ...    NaN   \n",
      "\n",
      "                                         description  company_industry  \\\n",
      "0  **ABOUT US**\\n\\n\\nSynthesize Bio is an early s...               NaN   \n",
      "1  Would you like to work for a software solution...               NaN   \n",
      "2  UnitedHealth Group is a health care and well\\-...               NaN   \n",
      "3  ### **Description**\\n\\n  \\n\\nWe are looking fo...               NaN   \n",
      "4  **Job Title:** Senior Data Engineer (Fully Rem...               NaN   \n",
      "\n",
      "                                         company_url  \\\n",
      "0                                                NaN   \n",
      "1  https://www.glassdoor.com/Overview/W-EI_IE2637...   \n",
      "2  https://www.glassdoor.com/Overview/W-EI_IE2409...   \n",
      "3  https://www.glassdoor.com/Overview/W-EI_IE3428...   \n",
      "4  https://www.glassdoor.com/Overview/W-EI_IE1019...   \n",
      "\n",
      "                                        company_logo company_url_direct  \\\n",
      "0                                                NaN                NaN   \n",
      "1  https://media.glassdoor.com/sql/263796/agreeya...                NaN   \n",
      "2  https://media.glassdoor.com/sql/2409113/optum-...                NaN   \n",
      "3  https://media.glassdoor.com/sql/3428499/course...                NaN   \n",
      "4  https://media.glassdoor.com/sql/1019753/aset-p...                NaN   \n",
      "\n",
      "  company_addresses company_num_employees company_revenue company_description  \n",
      "0               NaN                   NaN             NaN                 NaN  \n",
      "1               NaN                   NaN             NaN                 NaN  \n",
      "2               NaN                   NaN             NaN                 NaN  \n",
      "3               NaN                   NaN             NaN                 NaN  \n",
      "4               NaN                   NaN             NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "Number of jobs:  100\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "\n",
    "jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
    "    search_term=\"data engineer\",\n",
    "    results_wanted=25,\n",
    "    hours_old=72,\n",
    "    country_indeed='USA',\n",
    "    linkedin_fetch_description=True\n",
    "    # linkedin_fetch_description=True # gets more info such as description, direct job url (slower)\n",
    "    # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    ")\n",
    "print(f\"Found {len(jobs)} jobs\")\n",
    "print(jobs.head())\n",
    "print(\"Number of jobs: \", jobs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"jobs_de.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 23:39:31,464 - INFO - JobSpy:Indeed - search page: 1 / 1\n",
      "2024-12-11 23:39:31,482 - INFO - JobSpy:LinkedIn - search page: 1 / 3\n",
      "2024-12-11 23:39:31,627 - INFO - JobSpy:ZipRecruiter - search page: 1 / 2\n",
      "2024-12-11 23:39:32,052 - INFO - JobSpy:Glassdoor - search page: 1 / 2\n",
      "2024-12-11 23:39:32,228 - INFO - JobSpy:Indeed - finished scraping\n",
      "2024-12-11 23:39:32,255 - INFO - JobSpy:Google - search page: 1 / 3\n",
      "2024-12-11 23:39:32,984 - INFO - JobSpy:Glassdoor - finished scraping\n",
      "2024-12-11 23:39:33,248 - INFO - JobSpy:Google - search page: 2 / 3\n",
      "2024-12-11 23:39:33,562 - INFO - JobSpy:Google - search page: 3 / 3\n",
      "2024-12-11 23:39:33,874 - INFO - JobSpy:Google - finished scraping\n",
      "2024-12-11 23:39:37,684 - INFO - JobSpy:ZipRecruiter - search page: 2 / 2\n",
      "2024-12-11 23:39:38,644 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
      "2024-12-11 23:40:01,814 - ERROR - JobSpy:LinkedIn - LinkedIn: HTTPSConnectionPool(host='www.linkedin.com', port=443): Max retries exceeded with url: /jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=machine+learning+engineer&distance=50&pageNum=0&start=0&f_TPR=r259200 (Caused by ResponseError('too many 429 error responses'))\n",
      "2024-12-11 23:40:01,816 - INFO - JobSpy:Linkedin - finished scraping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 jobs\n",
      "                 id       site  \\\n",
      "0  gd-1009562410163  glassdoor   \n",
      "1  gd-1009562228616  glassdoor   \n",
      "2  gd-1009561787185  glassdoor   \n",
      "3  gd-1009561940918  glassdoor   \n",
      "4  gd-1009561787378  glassdoor   \n",
      "\n",
      "                                             job_url job_url_direct  \\\n",
      "0  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "1  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "2  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "3  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "4  https://www.glassdoor.com/job-listing/j?jl=100...            NaN   \n",
      "\n",
      "                                           title                   company  \\\n",
      "0  Bioinformatics Data Engineer - Open to Remote            Synthesize Bio   \n",
      "1                                  Data Engineer  Delmock Technologies Inc   \n",
      "2               Senior Customer Success Engineer  Switchboard Software Inc   \n",
      "3                               Backend Engineer                 PartsTech   \n",
      "4                            Onboarding Engineer          Net at Work, LLC   \n",
      "\n",
      "      location date_posted job_type salary_source  ... emails  \\\n",
      "0  Seattle, WA  2024-12-11      NaN           NaN  ...    NaN   \n",
      "1   Lanham, MD  2024-12-11      NaN   direct_data  ...    NaN   \n",
      "2          NaN  2024-12-11      NaN           NaN  ...    NaN   \n",
      "3          NaN  2024-12-11      NaN           NaN  ...    NaN   \n",
      "4          NaN  2024-12-11      NaN           NaN  ...    NaN   \n",
      "\n",
      "                                         description  company_industry  \\\n",
      "0  **ABOUT US**\\n\\n\\nSynthesize Bio is an early s...               NaN   \n",
      "1  About Our Company:\\n\\n\\nDelmock Technologies, ...               NaN   \n",
      "2  **About Switchboard**\\n=====================\\n...               NaN   \n",
      "3  PartsTech creates automotive e\\-commerce techn...               NaN   \n",
      "4  **About Cloud at Work**  \\n\\nCloud at Work, a ...               NaN   \n",
      "\n",
      "                                         company_url  \\\n",
      "0                                                NaN   \n",
      "1  https://www.glassdoor.com/Overview/W-EI_IE1176...   \n",
      "2  https://www.glassdoor.com/Overview/W-EI_IE1675...   \n",
      "3  https://www.glassdoor.com/Overview/W-EI_IE5187...   \n",
      "4  https://www.glassdoor.com/Overview/W-EI_IE1287...   \n",
      "\n",
      "                                        company_logo company_url_direct  \\\n",
      "0                                                NaN                NaN   \n",
      "1  https://media.glassdoor.com/sql/1176127/delmoc...                NaN   \n",
      "2  https://media.glassdoor.com/sql/1675906/switch...                NaN   \n",
      "3  https://media.glassdoor.com/sql/5187485/partst...                NaN   \n",
      "4  https://media.glassdoor.com/sql/1287290/net-at...                NaN   \n",
      "\n",
      "  company_addresses company_num_employees company_revenue company_description  \n",
      "0               NaN                   NaN             NaN                 NaN  \n",
      "1               NaN                   NaN             NaN                 NaN  \n",
      "2               NaN                   NaN             NaN                 NaN  \n",
      "3               NaN                   NaN             NaN                 NaN  \n",
      "4               NaN                   NaN             NaN                 NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "Number of jobs:  120\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from jobspy import scrape_jobs\n",
    "\n",
    "jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
    "    search_term=\"machine learning engineer\",\n",
    "    results_wanted=30,\n",
    "    hours_old=72,\n",
    "    country_indeed='USA',\n",
    "    linkedin_fetch_description=True\n",
    "    # linkedin_fetch_description=True # gets more info such as description, direct job url (slower)\n",
    "    # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    ")\n",
    "print(f\"Found {len(jobs)} jobs\")\n",
    "print(jobs.head())\n",
    "print(\"Number of jobs: \", jobs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv(\"jobs_mle.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
